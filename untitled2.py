# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Malini0605/PRODIGY_AI_01/blob/main/Untitled2.ipynb
"""

from google.colab import files
uploaded = files.upload()



from datasets import load_dataset

dataset = load_dataset("text", data_files={"train": "data.txt"})
print(dataset)

def add_labels(example):
    example["labels"] = example["input_ids"].copy()
    return example

tokenized_datasets = tokenized_datasets.map(add_labels)

from transformers import GPT2Tokenizer

tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

def tokenize_function(examples):
    return tokenizer(examples["text"], truncation=True, padding="max_length", max_length=128)

tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=["text"])
print(tokenized_datasets)

import os
os.environ["WANDB_DISABLED"] = "true"

from transformers import Trainer, TrainingArguments, AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained("gpt2")

training_args = TrainingArguments(
    output_dir="./gpt2-nature",
    per_device_train_batch_size=2,
    num_train_epochs=1,
    logging_steps=1,
    save_steps=5,
    save_total_limit=2,
    report_to="none"
)
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"]
)

trainer.train()
trainer.save_model("/content/gpt2-nature")
tokenizer.save_pretrained("/content/gpt2-nature")

!ls /content

from transformers import pipeline


generator = pipeline("text-generation", model="/content/gpt2-nature")


outputs = generator(
    "The beauty of nature is",
    max_new_tokens=60,
    num_return_sequences=3,
    temperature=0.9,
    top_k=50,
    top_p=0.95,
    repetition_penalty=1.2
)


for i, output in enumerate(outputs, 1):
    print(f"\nGenerated #{i}:\n{output['generated_text']}")

